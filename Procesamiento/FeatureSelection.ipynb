{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://http2.mlstatic.com/D_NQ_NP_2X_960089-MLM26807621582_022018-F.webp\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2022\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Selección de Variables</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La selección de variables es un proceso donde automáticamente se seleccionan aquellos atributos en nuestros datos que contribuyen más a la variable a predecir. \n",
    "\n",
    "Las variables irrelevantes o parcialmente relevantes pueden afectar negativamente el rendimiento del modelo.\n",
    "\n",
    "Beneficios:\n",
    "- Reducir sobreajuste: menos datos irrelevantes significan menos oportunidades de tomar decisiones basadas en ruido = mejor performance. \n",
    "- Modelo más fácil de entender\n",
    "- Reduce el tiempo de entrenamiento: menos datos significa que el modelo se entrena más rápido\n",
    "\n",
    "\n",
    "**Tipos de algoritmos de selección de variables**\n",
    "\n",
    "- **Supervisado**: se basa la selección en la variable objetivo.\n",
    "\n",
    "    - Métodos de envoltura: se considera como un problema de búsqueda la selección de un conjunto de variables donde diferentes combinaciones se preparan, evalúan y comparan con otras combinaciones. Se utiliza un modelo predictivo para evaluar una combinación de características y asignar un score basado en la precisión del modelo. \n",
    "        - Ejemplo: RFE\n",
    "\n",
    "    - Métodos de filtrado: estos métodos aplican una medida estadística para asignar una puntuación a cada característica. Las características se clasifican según la puntuación y se seleccionan para conservarlas o eliminarlas del conjunto de datos. Los métodos suelen ser univariados y consideran la característica de forma independiente o con respecto a la variable dependiente.\n",
    "        - Ejemplo: prueba de chi cuadrada, L-Anova\n",
    "\n",
    "    - Métodos embebidos: mientras se va creando el modelo el método aprende qué características contribuyen mejor a la precisión. El método más común es el de regularización. \n",
    "        - Ejemplo: LASSO, Elastic Net, Ridge, Trees\n",
    "\n",
    "- **No supervisado**: se ignora a la variable objetivo para seleccionar las variables. \n",
    "\n",
    "Ejemplo: método de correlación, criterio de la varianza\n",
    "\n",
    "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/11/Overview-of-Feature-Selection-Techniques3.png\" width=\"550\" height=\"480\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mencionando algunas técnicas más comunes:**\n",
    "\n",
    "- Porcentaje de valores nulos\n",
    "- Cantidad de variación\n",
    "- Correlación por parejas\n",
    "- Mulicolinealidad\n",
    "- PCA\n",
    "- Correlación con la variable a predecir (target)\n",
    "- Forward Selection\n",
    "- Backward Selection\n",
    "- Stepwise Selection\n",
    "- LASSO\n",
    "- Selección basada en árboles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de variables\n",
    "\n",
    "La decisión de qué medida estadística utilizar en muchos casos depende del tipo de las variables. \n",
    "\n",
    "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2020/06/Overview-of-Data-Variable-Types2.png\" width=\"550\" height=\"480\" align=\"center\"/>\n",
    "\n",
    "Entre más se sepa del tipo de variable es más fácil elegir qué medida estadística se va a utilizar, sobre todo para los métodos de filtrado \n",
    "\n",
    "**¿Cómo elegir las mejores variables?**\n",
    "No es una respuesta fácil, hay que tratar de varias formas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos: Glass Identification Data Set\n",
    "Los datos se pueden encontrar en:\n",
    "https://archive.ics.uci.edu/ml/datasets/glass+identification\n",
    "\n",
    "Se busca identificar qué tipo de vidrio es una muestra. \n",
    "\n",
    "\n",
    "- 1. Id number: 1 a 214\n",
    "- 2. RI: Indice Refractivo(medida para saber cuánto se reduce la velocidad de la luz al atravesarlo)\n",
    "- 3. Na: Sodio (unidad de medida: porcentaje en peso en el óxido correspondiente, como son los atributos 4-10)\n",
    "- 4. Mg: Magenesio\n",
    "- 5. Al: Aluminio\n",
    "- 6. Si: Silicon\n",
    "- 7. K: Potasio\n",
    "- 8. Ca: Calcio\n",
    "- 9. Ba: Bario\n",
    "- 10. Fe: Hierro\n",
    "- 11. Tipo de Vidrio: \n",
    "-- 1 ventanas de edificios procesadas por flotación \n",
    "-- 2 ventanas de edificios no procesadas por flotación \n",
    "-- 3 ventanas de vehículos procesadas por flotación\n",
    "-- 4 ventanas de vehículos no procesadas por flotación \n",
    "-- 5 contenedores\n",
    "-- 6 vajilla\n",
    "-- 7 faros\n",
    "\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://archive.ics.uci.edu/ml/assets/logo.gif\" width=\"350px\" height=\"180px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'glass.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-49b50a5b6035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Cargar datos del vidrio (variable a predecir categórica)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'glass.data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Indice_Refraccion'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Na'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Mg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Al'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Si'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Ca'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Ba'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Fe'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Tipo_Vidrio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'glass.data'"
     ]
    }
   ],
   "source": [
    "#Importar librerías\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar datos del vidrio (variable a predecir categórica)\n",
    "data = pd.read_csv('glass.data',header=None)\n",
    "names = ['ID','Indice_Refraccion','Na','Mg','Al','Si','K', 'Ca','Ba','Fe','Tipo_Vidrio']\n",
    "data.columns = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de Filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos de eliminación sólo variables predictoras (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar variable con % de datos nulos\n",
    "\n",
    "Cuando hay muchos datos nulos, es difícil para el algoritmo aprender de esos datos (ya que no hay nada)\n",
    "\n",
    "Hay 2 opciones:\n",
    "1. Quitar variables que tienen un % alto de datos nulos\n",
    "\n",
    "   (\\# de datos con valores nulos/ \\# total de datos) \n",
    "   \n",
    "   \n",
    "2. Crear indicadores binarios que explícitamente digan existente / valor nulo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterio de la Varianza\n",
    "\n",
    "Este algoritmo se enfoca sólo en las variables independientes (X) y NO en la variables a predecir (y), por eso se le puede usar para aprendizaje no supervisado. \n",
    "\n",
    "Si la variable tiene casi los mismos valores, entonces el modelo no va a aprender nada de esa variable. \n",
    "\n",
    "\n",
    "$$\\begin{matrix} 5 & 19 & 6.8 & 100 & 22\\\\ 5 & 25 & 7.2 & 150 & 23\\\\ 5 & 15 & 4.5 & 90 & 19\\\\ 4 & 30 & 8.9 & 125 & 25\\\\ 5 & 18 & 9.5 & 75 & 15\\\\\\end{matrix}$$\n",
    "\n",
    "Se recomienda estandarizar todas las variables para tomar encuenta las diferentes escalas.\n",
    "\n",
    "Por lo general se remueven las variables con varianza muy cercana a cero. \n",
    "\n",
    "Métricas de evaluación:\n",
    "- Con un umbral de varianza. Se remueven las variables cuya varianza no alcanza el límite propuesto. \n",
    "- La proporción entre valores únicos y el total de muestras es bajo $\\frac{Valores_{unicos}}{muestras_{totales}}<0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tomamos sólo variables de interés (variables predictoras X)\n",
    "data.iloc[:,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizar los datos\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "names = data.columns[1:10]\n",
    "d = scaler.fit_transform(data.iloc[:,1:10])\n",
    "scaled_df = pd.DataFrame(d, columns=names)\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbral de la varianza (threshold) A Mano\n",
    "\n",
    "varianzas = pd.DataFrame(scaled_df.var().sort_values(),columns=[\"Varianza\"])\n",
    "\n",
    "def addlabels(x,y):\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i,round(y[i],3),round(y[i],3))\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.bar(np.arange(len(varianzas)),varianzas.Varianza)\n",
    "plt.ylabel('Varianza')\n",
    "plt.xticks(np.arange(len(varianzas)),varianzas.index,rotation=90)\n",
    "addlabels(np.arange(len(varianzas)), varianzas.Varianza)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿A mano cómo selecciono las variables una vez calculada la varianza?\n",
    "\n",
    "Selecciono un \"threshold\" o valor, como límite para tomar mi decisión. \n",
    "Por ejemplo:\n",
    "\n",
    "Yo quiero sólo quedarme con los datos que varíen más de 0.02\n",
    "\n",
    "Threhold = 0.02\n",
    "\n",
    "Por lo tanto, me quedo sólo con las variables de: Al, Ba, Fe y Mg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Con librería\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=0.02)\n",
    "sel.fit_transform(scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué significa este resultado? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Qué pasa si tenemos datos con variables dicotómicas/binarias?*\n",
    "\n",
    "Supongamos que tenemos un dataset con variables dicotómicas y queremos remover todos los atributos que sean uno o cero en más del 80% de la muestra. \n",
    "\n",
    "$$\\begin{matrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\\\ 0& 1 & 1 \\\\ 0 & 1 & 0 \\\\  0 & 1 & 1 \\end{matrix}$$\n",
    "\n",
    "Las variables dicotómicas son variables aleatorios de Bernoulli, y la varianza está dada por:\n",
    "\n",
    "$$Var[x]=p*(1-p)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "sel.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método quitó la primer columna, que tiene una probabilidad de p=5/6>0.8 de contener un cero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterio de la correlación entre pares (sin tomar en cuenta la variable target \"Y\")\n",
    "\n",
    "$$y=\\beta_{0}+\\beta_{1}X_{1}+\\beta_{2}X_{2}+...+\\epsilon$$\n",
    "\n",
    "Cuando existe correlación entre 2 variables predictoras \"X\", no podemos determinar el efecto de una 1 variable tomando en cuenta que la otra variable es constante ya que las dos variables cambian juntas. \n",
    "\n",
    "Cuando se tienen variables relacionadas, se puede considerar que todas las variables proporcionan la misma información al modelo. Por lo que, es deseable seleccionar solo variables que no estén relacionadas y evitar redundancia de información.\n",
    "\n",
    "Si dos variables están altamente correlacionadas, dejar sólo una va a ayudar a reducir la dimensionalidad sin perder mucha información.\n",
    "\n",
    "La matriz de correlaciones puede ayudar a visualizar si existen variables candidatas a ser descartadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar X de Y\n",
    "X = data.iloc[:,1:10]\n",
    "Y = data.iloc[:,10]\n",
    "\n",
    "co= X.corr()\n",
    "co.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Y ahora?\n",
    "\n",
    "1. Determinar la matriz de correlaciones de las variables\n",
    "2. Determinar el par de variables con correlación más alta. (𝑋𝑎 y 𝑋𝑏)\n",
    "3. Determinar el promedio de la correlación de 𝑋𝑎 contra todas las demás variables, y hacer lo mismo para 𝑋𝑏.\n",
    "4. Se remueve la variable con mayor correlación promedio.\n",
    "5. Repetir los pasos 2-4 hasta que las correlaciones de mantengan por debajo de un umbral deseado (𝜌𝑋𝑎𝑋𝑏<0.75).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_prom_Xa= (-.19-.12-.41-.54-.29+.81+.14)/8  #Indice Refraccion\n",
    "corr_prom_Xb = (.81-.28-.4-.26-.21-.32-.11+.12)/8  #Calcio\n",
    "print(corr_prom_Xa) #Indice Refraccion\n",
    "print(corr_prom_Xb) #Calcio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto quitamos el índice de refracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevasX=X.iloc[:,1:9]\n",
    "nuevasX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co= nuevasX.corr()\n",
    "co.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos sólo la variable \"Índice de Refracción\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos de eliminación tomando en cuenta X y Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterio de la correlación contra la variable target \"Y\"\n",
    "\n",
    "- Eliminar variables que tienen una correlación baja con la variable a predecir\n",
    "\n",
    "- Si una variable tiene baja correlación con el target, no va a ser útil para la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co= data.iloc[:,1:11].corr()\n",
    "co.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso yo podría quitar la variable de \"Ca\" ya que no tiene correlación con la variable a predecir \"Tipo de Vidrio\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de Envoltura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación Recursiva de Características\n",
    "\n",
    "Funciona eliminando atributos de forma recursiva y construyendo un modelo sobre los atributos que quedan.\n",
    "\n",
    "Usa la precisión del modelo para identificar qué atributos (y combinación de atributos) contribuyen más a predecir el objetivo.\n",
    "\n",
    "Vamos a utilizar la regresión logística para seleccionar las 4 características principales. La elección del algoritmo no importa demasiado siempre que sea hábil y consistente con el tipo de problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#crear modelo de regresión logística\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "#crear el recursive feature elimination para la regresión logística, seleccionando sólo 4 variables\n",
    "rfe = RFE(model, n_features_to_select= 4)\n",
    "#ajusta modelo\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"# de características: %d\" % fit.n_features_)\n",
    "print(\"Características seleccionadas: %s\" % fit.support_)\n",
    "print(\"Rank de las características: %s\" % fit.ranking_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[:, fit.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El RFE eligió las siguientes variables: Mg, Al, K, Ba \n",
    "Están marcadas como \"True\" o como \"1\". \n",
    "De igual manera, los resultados pueden variar dependiendo de la naturaleza estocástica del algoritmo o el proceso de evaluación, o diferencias en la precisión numérica. Se recomienda correr el ejercicio varias veces para comparar el resultado promedio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos embebidos (intrínsecos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables basada en árboles\n",
    "\n",
    "Modelos basados en árboles como el \"Random Forest\" y los \"Extra Trees\" ya tienen dentro de su proceso un método de seleción de variables donde estiman la importancia de los atributos. \n",
    "\n",
    "Construimos un Clasificador de \"Extra Tree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance con clasificador de Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# crear objeto de Extra Trees\n",
    "model = ExtraTreesClassifier(n_estimators=10)\n",
    "#Ajustar modelo a datos\n",
    "model.fit(X, Y)\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute':data.iloc[:,1:10].columns, \n",
    "    'Importance': model.feature_importances_\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las 4 variables más importantes serían: Mg, Al, Ca e Indice de Refraccion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='#087E8B')\n",
    "plt.title('Importancia de los atributos obtenido de los coeficientes', size=15)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización Least Absolute Shrinkage and Selection Operator (LASSO)\n",
    "\n",
    "Lo que hace LASSO es que tiene un parámetro de regularización que penaliza a algunas variables y las hace cero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar en datos de entrenamiento y de prueba\n",
    "X= data.drop(labels=['ID', 'Tipo_Vidrio'], axis=1)\n",
    "Y= data['Tipo_Vidrio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoría de los modelos lineales se benefician de escalar los datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalar datos de entrenamiento\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##LASSO\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "sel=LogisticRegression(C=1, penalty='l1', solver='liblinear').fit(X,Y)\n",
    "sel=SelectFromModel(sel, prefit=True)\n",
    "X_new=sel.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuál es el mejor método?\n",
    "\n",
    "...no hay...\n",
    "\n",
    "Se tiene que hacer experimentación para ver qué método funciona mejor para el problema en específico. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias:\n",
    "\n",
    "- Comparison of F-test and mutual information: https://scikit-learn.org/stable/auto_examples/feature_selection/plot_f_test_vs_mi.html#sphx-glr-auto-examples-feature-selection-plot-f-test-vs-mi-py\n",
    "- Feature selection: https://scikit-learn.org/stable/modules/feature_selection.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Sara E. Rodríguez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
