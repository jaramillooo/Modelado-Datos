{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://http2.mlstatic.com/D_NQ_NP_2X_960089-MLM26807621582_022018-F.webp\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodr铆guez </Strong>\n",
    "- <Strong> A帽o </Strong>: 2022\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Selecci贸n de Variables</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La selecci贸n de variables es un proceso donde autom谩ticamente se seleccionan aquellos atributos en nuestros datos que contribuyen m谩s a la variable a predecir. \n",
    "\n",
    "Las variables irrelevantes o parcialmente relevantes pueden afectar negativamente el rendimiento del modelo.\n",
    "\n",
    "Beneficios:\n",
    "- Reducir sobreajuste: menos datos irrelevantes significan menos oportunidades de tomar decisiones basadas en ruido = mejor performance. \n",
    "- Modelo m谩s f谩cil de entender\n",
    "- Reduce el tiempo de entrenamiento: menos datos significa que el modelo se entrena m谩s r谩pido\n",
    "\n",
    "\n",
    "**Tipos de algoritmos de selecci贸n de variables**\n",
    "\n",
    "- **Supervisado**: se basa la selecci贸n en la variable objetivo.\n",
    "\n",
    "    - M茅todos de envoltura: se considera como un problema de b煤squeda la selecci贸n de un conjunto de variables donde diferentes combinaciones se preparan, eval煤an y comparan con otras combinaciones. Se utiliza un modelo predictivo para evaluar una combinaci贸n de caracter铆sticas y asignar un score basado en la precisi贸n del modelo. \n",
    "        - Ejemplo: RFE\n",
    "\n",
    "    - M茅todos de filtrado: estos m茅todos aplican una medida estad铆stica para asignar una puntuaci贸n a cada caracter铆stica. Las caracter铆sticas se clasifican seg煤n la puntuaci贸n y se seleccionan para conservarlas o eliminarlas del conjunto de datos. Los m茅todos suelen ser univariados y consideran la caracter铆stica de forma independiente o con respecto a la variable dependiente.\n",
    "        - Ejemplo: prueba de chi cuadrada, L-Anova\n",
    "\n",
    "    - M茅todos embebidos: mientras se va creando el modelo el m茅todo aprende qu茅 caracter铆sticas contribuyen mejor a la precisi贸n. El m茅todo m谩s com煤n es el de regularizaci贸n. \n",
    "        - Ejemplo: LASSO, Elastic Net, Ridge, Trees\n",
    "\n",
    "- **No supervisado**: se ignora a la variable objetivo para seleccionar las variables. \n",
    "\n",
    "Ejemplo: m茅todo de correlaci贸n, criterio de la varianza\n",
    "\n",
    "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/11/Overview-of-Feature-Selection-Techniques3.png\" width=\"550\" height=\"480\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mencionando algunas t茅cnicas m谩s comunes:**\n",
    "\n",
    "- Porcentaje de valores nulos\n",
    "- Cantidad de variaci贸n\n",
    "- Correlaci贸n por parejas\n",
    "- Mulicolinealidad\n",
    "- PCA\n",
    "- Correlaci贸n con la variable a predecir (target)\n",
    "- Forward Selection\n",
    "- Backward Selection\n",
    "- Stepwise Selection\n",
    "- LASSO\n",
    "- Selecci贸n basada en 谩rboles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de variables\n",
    "\n",
    "La decisi贸n de qu茅 medida estad铆stica utilizar en muchos casos depende del tipo de las variables. \n",
    "\n",
    "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2020/06/Overview-of-Data-Variable-Types2.png\" width=\"550\" height=\"480\" align=\"center\"/>\n",
    "\n",
    "Entre m谩s se sepa del tipo de variable es m谩s f谩cil elegir qu茅 medida estad铆stica se va a utilizar, sobre todo para los m茅todos de filtrado \n",
    "\n",
    "**驴C贸mo elegir las mejores variables?**\n",
    "No es una respuesta f谩cil, hay que tratar de varias formas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos: Glass Identification Data Set\n",
    "Los datos se pueden encontrar en:\n",
    "https://archive.ics.uci.edu/ml/datasets/glass+identification\n",
    "\n",
    "Se busca identificar qu茅 tipo de vidrio es una muestra. \n",
    "\n",
    "\n",
    "- 1. Id number: 1 a 214\n",
    "- 2. RI: Indice Refractivo(medida para saber cu谩nto se reduce la velocidad de la luz al atravesarlo)\n",
    "- 3. Na: Sodio (unidad de medida: porcentaje en peso en el 贸xido correspondiente, como son los atributos 4-10)\n",
    "- 4. Mg: Magenesio\n",
    "- 5. Al: Aluminio\n",
    "- 6. Si: Silicon\n",
    "- 7. K: Potasio\n",
    "- 8. Ca: Calcio\n",
    "- 9. Ba: Bario\n",
    "- 10. Fe: Hierro\n",
    "- 11. Tipo de Vidrio: \n",
    "-- 1 ventanas de edificios procesadas por flotaci贸n \n",
    "-- 2 ventanas de edificios no procesadas por flotaci贸n \n",
    "-- 3 ventanas de veh铆culos procesadas por flotaci贸n\n",
    "-- 4 ventanas de veh铆culos no procesadas por flotaci贸n \n",
    "-- 5 contenedores\n",
    "-- 6 vajilla\n",
    "-- 7 faros\n",
    "\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://archive.ics.uci.edu/ml/assets/logo.gif\" width=\"350px\" height=\"180px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'glass.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-49b50a5b6035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Cargar datos del vidrio (variable a predecir categ贸rica)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'glass.data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Indice_Refraccion'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Na'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Mg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Al'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Si'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Ca'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Ba'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Fe'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Tipo_Vidrio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'glass.data'"
     ]
    }
   ],
   "source": [
    "#Importar librer铆as\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar datos del vidrio (variable a predecir categ贸rica)\n",
    "data = pd.read_csv('glass.data',header=None)\n",
    "names = ['ID','Indice_Refraccion','Na','Mg','Al','Si','K', 'Ca','Ba','Fe','Tipo_Vidrio']\n",
    "data.columns = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M茅todos de Filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M茅todos de eliminaci贸n s贸lo variables predictoras (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar variable con % de datos nulos\n",
    "\n",
    "Cuando hay muchos datos nulos, es dif铆cil para el algoritmo aprender de esos datos (ya que no hay nada)\n",
    "\n",
    "Hay 2 opciones:\n",
    "1. Quitar variables que tienen un % alto de datos nulos\n",
    "\n",
    "   (\\# de datos con valores nulos/ \\# total de datos) \n",
    "   \n",
    "   \n",
    "2. Crear indicadores binarios que expl铆citamente digan existente / valor nulo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterio de la Varianza\n",
    "\n",
    "Este algoritmo se enfoca s贸lo en las variables independientes (X) y NO en la variables a predecir (y), por eso se le puede usar para aprendizaje no supervisado. \n",
    "\n",
    "Si la variable tiene casi los mismos valores, entonces el modelo no va a aprender nada de esa variable. \n",
    "\n",
    "\n",
    "$$\\begin{matrix} 5 & 19 & 6.8 & 100 & 22\\\\ 5 & 25 & 7.2 & 150 & 23\\\\ 5 & 15 & 4.5 & 90 & 19\\\\ 4 & 30 & 8.9 & 125 & 25\\\\ 5 & 18 & 9.5 & 75 & 15\\\\\\end{matrix}$$\n",
    "\n",
    "Se recomienda estandarizar todas las variables para tomar encuenta las diferentes escalas.\n",
    "\n",
    "Por lo general se remueven las variables con varianza muy cercana a cero. \n",
    "\n",
    "M茅tricas de evaluaci贸n:\n",
    "- Con un umbral de varianza. Se remueven las variables cuya varianza no alcanza el l铆mite propuesto. \n",
    "- La proporci贸n entre valores 煤nicos y el total de muestras es bajo $\\frac{Valores_{unicos}}{muestras_{totales}}<0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tomamos s贸lo variables de inter茅s (variables predictoras X)\n",
    "data.iloc[:,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizar los datos\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "names = data.columns[1:10]\n",
    "d = scaler.fit_transform(data.iloc[:,1:10])\n",
    "scaled_df = pd.DataFrame(d, columns=names)\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbral de la varianza (threshold) A Mano\n",
    "\n",
    "varianzas = pd.DataFrame(scaled_df.var().sort_values(),columns=[\"Varianza\"])\n",
    "\n",
    "def addlabels(x,y):\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i,round(y[i],3),round(y[i],3))\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.bar(np.arange(len(varianzas)),varianzas.Varianza)\n",
    "plt.ylabel('Varianza')\n",
    "plt.xticks(np.arange(len(varianzas)),varianzas.index,rotation=90)\n",
    "addlabels(np.arange(len(varianzas)), varianzas.Varianza)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "驴A mano c贸mo selecciono las variables una vez calculada la varianza?\n",
    "\n",
    "Selecciono un \"threshold\" o valor, como l铆mite para tomar mi decisi贸n. \n",
    "Por ejemplo:\n",
    "\n",
    "Yo quiero s贸lo quedarme con los datos que var铆en m谩s de 0.02\n",
    "\n",
    "Threhold = 0.02\n",
    "\n",
    "Por lo tanto, me quedo s贸lo con las variables de: Al, Ba, Fe y Mg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Con librer铆a\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=0.02)\n",
    "sel.fit_transform(scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "驴Qu茅 significa este resultado? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*驴Qu茅 pasa si tenemos datos con variables dicot贸micas/binarias?*\n",
    "\n",
    "Supongamos que tenemos un dataset con variables dicot贸micas y queremos remover todos los atributos que sean uno o cero en m谩s del 80% de la muestra. \n",
    "\n",
    "$$\\begin{matrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\\\ 0& 1 & 1 \\\\ 0 & 1 & 0 \\\\  0 & 1 & 1 \\end{matrix}$$\n",
    "\n",
    "Las variables dicot贸micas son variables aleatorios de Bernoulli, y la varianza est谩 dada por:\n",
    "\n",
    "$$Var[x]=p*(1-p)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "sel.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El m茅todo quit贸 la primer columna, que tiene una probabilidad de p=5/6>0.8 de contener un cero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterio de la correlaci贸n entre pares (sin tomar en cuenta la variable target \"Y\")\n",
    "\n",
    "$$y=\\beta_{0}+\\beta_{1}X_{1}+\\beta_{2}X_{2}+...+\\epsilon$$\n",
    "\n",
    "Cuando existe correlaci贸n entre 2 variables predictoras \"X\", no podemos determinar el efecto de una 1 variable tomando en cuenta que la otra variable es constante ya que las dos variables cambian juntas. \n",
    "\n",
    "Cuando se tienen variables relacionadas, se puede considerar que todas las variables proporcionan la misma informaci贸n al modelo. Por lo que, es deseable seleccionar solo variables que no est茅n relacionadas y evitar redundancia de informaci贸n.\n",
    "\n",
    "Si dos variables est谩n altamente correlacionadas, dejar s贸lo una va a ayudar a reducir la dimensionalidad sin perder mucha informaci贸n.\n",
    "\n",
    "La matriz de correlaciones puede ayudar a visualizar si existen variables candidatas a ser descartadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar X de Y\n",
    "X = data.iloc[:,1:10]\n",
    "Y = data.iloc[:,10]\n",
    "\n",
    "co= X.corr()\n",
    "co.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "驴Y ahora?\n",
    "\n",
    "1. Determinar la matriz de correlaciones de las variables\n",
    "2. Determinar el par de variables con correlaci贸n m谩s alta. ( y )\n",
    "3. Determinar el promedio de la correlaci贸n de  contra todas las dem谩s variables, y hacer lo mismo para .\n",
    "4. Se remueve la variable con mayor correlaci贸n promedio.\n",
    "5. Repetir los pasos 2-4 hasta que las correlaciones de mantengan por debajo de un umbral deseado (<0.75).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_prom_Xa= (-.19-.12-.41-.54-.29+.81+.14)/8  #Indice Refraccion\n",
    "corr_prom_Xb = (.81-.28-.4-.26-.21-.32-.11+.12)/8  #Calcio\n",
    "print(corr_prom_Xa) #Indice Refraccion\n",
    "print(corr_prom_Xb) #Calcio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto quitamos el 铆ndice de refracci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevasX=X.iloc[:,1:9]\n",
    "nuevasX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co= nuevasX.corr()\n",
    "co.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos s贸lo la variable \"ndice de Refracci贸n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M茅todos de eliminaci贸n tomando en cuenta X y Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterio de la correlaci贸n contra la variable target \"Y\"\n",
    "\n",
    "- Eliminar variables que tienen una correlaci贸n baja con la variable a predecir\n",
    "\n",
    "- Si una variable tiene baja correlaci贸n con el target, no va a ser 煤til para la predicci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co= data.iloc[:,1:11].corr()\n",
    "co.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso yo podr铆a quitar la variable de \"Ca\" ya que no tiene correlaci贸n con la variable a predecir \"Tipo de Vidrio\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M茅todos de Envoltura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminaci贸n Recursiva de Caracter铆sticas\n",
    "\n",
    "Funciona eliminando atributos de forma recursiva y construyendo un modelo sobre los atributos que quedan.\n",
    "\n",
    "Usa la precisi贸n del modelo para identificar qu茅 atributos (y combinaci贸n de atributos) contribuyen m谩s a predecir el objetivo.\n",
    "\n",
    "Vamos a utilizar la regresi贸n log铆stica para seleccionar las 4 caracter铆sticas principales. La elecci贸n del algoritmo no importa demasiado siempre que sea h谩bil y consistente con el tipo de problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#crear modelo de regresi贸n log铆stica\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "#crear el recursive feature elimination para la regresi贸n log铆stica, seleccionando s贸lo 4 variables\n",
    "rfe = RFE(model, n_features_to_select= 4)\n",
    "#ajusta modelo\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"# de caracter铆sticas: %d\" % fit.n_features_)\n",
    "print(\"Caracter铆sticas seleccionadas: %s\" % fit.support_)\n",
    "print(\"Rank de las caracter铆sticas: %s\" % fit.ranking_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[:, fit.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El RFE eligi贸 las siguientes variables: Mg, Al, K, Ba \n",
    "Est谩n marcadas como \"True\" o como \"1\". \n",
    "De igual manera, los resultados pueden variar dependiendo de la naturaleza estoc谩stica del algoritmo o el proceso de evaluaci贸n, o diferencias en la precisi贸n num茅rica. Se recomienda correr el ejercicio varias veces para comparar el resultado promedio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M茅todos embebidos (intr铆nsecos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecci贸n de variables basada en 谩rboles\n",
    "\n",
    "Modelos basados en 谩rboles como el \"Random Forest\" y los \"Extra Trees\" ya tienen dentro de su proceso un m茅todo de seleci贸n de variables donde estiman la importancia de los atributos. \n",
    "\n",
    "Construimos un Clasificador de \"Extra Tree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance con clasificador de Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# crear objeto de Extra Trees\n",
    "model = ExtraTreesClassifier(n_estimators=10)\n",
    "#Ajustar modelo a datos\n",
    "model.fit(X, Y)\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute':data.iloc[:,1:10].columns, \n",
    "    'Importance': model.feature_importances_\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las 4 variables m谩s importantes ser铆an: Mg, Al, Ca e Indice de Refraccion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='#087E8B')\n",
    "plt.title('Importancia de los atributos obtenido de los coeficientes', size=15)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularizaci贸n Least Absolute Shrinkage and Selection Operator (LASSO)\n",
    "\n",
    "Lo que hace LASSO es que tiene un par谩metro de regularizaci贸n que penaliza a algunas variables y las hace cero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar en datos de entrenamiento y de prueba\n",
    "X= data.drop(labels=['ID', 'Tipo_Vidrio'], axis=1)\n",
    "Y= data['Tipo_Vidrio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayor铆a de los modelos lineales se benefician de escalar los datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalar datos de entrenamiento\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##LASSO\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "sel=LogisticRegression(C=1, penalty='l1', solver='liblinear').fit(X,Y)\n",
    "sel=SelectFromModel(sel, prefit=True)\n",
    "X_new=sel.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 驴Cu谩l es el mejor m茅todo?\n",
    "\n",
    "...no hay...\n",
    "\n",
    "Se tiene que hacer experimentaci贸n para ver qu茅 m茅todo funciona mejor para el problema en espec铆fico. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias:\n",
    "\n",
    "- Comparison of F-test and mutual information: https://scikit-learn.org/stable/auto_examples/feature_selection/plot_f_test_vs_mi.html#sphx-glr-auto-examples-feature-selection-plot-f-test-vs-mi-py\n",
    "- Feature selection: https://scikit-learn.org/stable/modules/feature_selection.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Sara E. Rodr铆guez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
